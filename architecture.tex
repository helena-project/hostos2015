\section{\name: a Secure Embedded OS}

In our ongoing project, \name, we are building a new embedded operating system
specifically designed for platforms running multiple, potentially untrusted
applications concurrently and third-party, contributed device drivers that are
assumed to be buggy. \name uses three protection mechanisms to protect three
different components in the operating system. The kernel itself is written in
Rust, allowing \name to use language level protection, such as memory safety and
ownership, to protect the core of the kernel (e.g. the scheduler and hardware
abstraction layer) from contributed device drivers. \name uses software managed
memory protection to isolate third-party applications from each other and the
kernel. Finally, where available, multiple microcontrollers on the same platform
are use to protect applications with timing constraints against starvation and
in cases where timing and other side-channels are a concern. The remainder of
this section gives an overview of the \name architecture and dives into \name's
use of the memory protection unit and application memory layout.

\subsection{Architecture}

In traditional embedded operating systems, a single application is
compiled along with a library operating system to a single executable that is
loaded on to the target device. The application, device drivers, scheduler, and
other OS services run with the same CPU privileges, share memory and have equal access
to the same hardware resources. \name takes a radically different approach. In
\name, there is a standalone, portable kernel that is composed, at compile-time,
with approriate device drivers for the platform and enables dynamic loading of
third-party applications at runtime.

At a high level, \name has three layers of computational units. At the lowest
layer, the core of the kernel---the scheduler, task manager, hardware
abstraction layer, etc---has completely control of the hardware, including
memory-unsafe and thread-unsafe operations such as writing to arbitrary memory
and turning interrupts on and off. A device driver runs with the same
\emph{hardware} privileges as the core kernel but inside a compile time,
\emph{language-level} sandbox. The language sandbox enforces that device drivers
can only use the kernel provided hardware abstractions to access hardware, that
dynamic memory allocation is limited to load time and stack allocation, and that
drivers cannot interfere with each other by accidentally sharing underlying
hardware resources.

The third layer, where applications run, is isolated using hardware protection
mechanisms. Applications, which do not have to be written in Rust, run in an
unprivileged CPU mode that restricts access to privileged CPU and hardware
registers, such as the control and program status CPU registers and the memory
protection unit hardware registers. Applications can access hardware resources
in two ways. First, through a system call interface exposed by the kernel and
device drivers.  Second, the kernel can give an application direct read and/or
write access to particular hardware registers.


\subsection{The Cortex-M MPU}

The Cortex-M MPU allows the kernel to defined eight memory regions. Each memory
region may be sized between 32 bytes and 4GB, in 32 byte increments and has
protection bits for read, write and execute. Regions may overlap, in which case
the memory region with the highest number ``wins''. In addition, regions of at
least 256 bytes can be divided into eight equal sized subregions, which can
either be turned on---in which case they inheret the parent region's protection
bits---or turned off---in which case the parent's protection bits do not apply.
As a result, the operating system can control access to up to 64 concurrently
active regions. Finally, memory regions and protection bits can be changed
during exection, for example while context switching between applications.

\subsection{Memory Regions in \name}

Unlike desktop operating systems, microcontrollers with memory protection have
no support for virtual addressing. As a result, any executing thread can attempt
load and store operations to any address in memory, including sensitive kernel
buffers or hardware memory registers. The memory protection unit (MPU) allows an
operating system to protect sensitive memory regions from malicious or buggy
applications by marking memory regions with read, write and execute permission.
These permission take effect when the processor is in unprivileged mode.
However, using access control instead of virtual memory for protection requires
well behaved applications to know exactly where memory regions reside and which
regions it has access to.

The operating system has roles with respect to application memory. First it
manages where applications are allowed to allocate memory. Second it manages
which memories the application can access. This includes most of the application
allocated memory, but may also include hardware memory registers that are
exposed directly to applications.

{\bf Allocation Regions.} 
In \name, the kernel allocates three separate memory regions for each
application, one for each of the stack, heap and data sections. The stack and
data sections are completely accessible to the application, and only the
application can allocate memory there. On the other hand, the heap is shared
between the application and the kernel, which \emph{borrows} heap memory from
the application for things like buffers and queues which the kernel needs
to satisfy application demands.

{\bf Access Rules.}
Naively, memory allocation rules would define memory access rules. For example,
in \name, applications would have read and write access to their stack, heap and
data regions and execute access to their code segments, while all other memory
accesses would be mediated through the kernel via system calls. However, this
approach has two main deficiencies:

\begin{enumerate}
  \item The kernel must choose between dynamically allocating memory in response to
  application requests in kernel memory or compromising on the integrity of
  kernel data structures.

  \item It needlessly increases the complexity of accessing hardware resources
  that are common in embedded applications such as the GPIO.

\end{enumerate}

Instead, \name treats allocation and access control separately. Applications are
given complete access (read and write) to their stack and data segments.
However, the heap is divided between the kernel and application---the
application heap grows up while the application-specific kernel heap grows down.
The boundry between the two changes dynamically as memory is allocated to
maximize utilization. In the case that an application heap is exhausted, either
by the applicatoin itself or by the kernel, the application is terminated and
restarted, without effect on the kernel.

